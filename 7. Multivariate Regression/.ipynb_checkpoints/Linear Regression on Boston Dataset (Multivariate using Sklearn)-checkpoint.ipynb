{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "x = boston.data # contains examples with features\n",
    "y = boston.target # contains results\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (404,)\n",
      "(102, 13) (102,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into training and testing samples \n",
    "# using sklearn to split the data or can be done manually too\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.08489931e-01  5.51955142e-02  3.78275929e-02  1.98104872e+00\n",
      " -1.87434169e+01  3.67082294e+00 -1.11445723e-03 -1.54285954e+00\n",
      "  3.09223123e-01 -1.40738095e-02 -9.66088699e-01  8.93183244e-03\n",
      " -4.81882139e-01]\n",
      "38.275989048391416\n"
     ]
    }
   ],
   "source": [
    "# Training our regression model can be done in two ways, either writting whole code from scratch or using sklearn to do so\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Our model will learn total of 14 parameters, 13 parameters for each feature and an additional one for the intercept(theta_not)\n",
    "lr = LinearRegression(normalize = True) # created an lr object of class LinearRegression, by default normalisation is false\n",
    "lr.fit(x_train, y_train) # this will train the model by providing it dataset values and generate the parameters(theta)\n",
    "print(lr.coef_) # refers to all the remaining parameters apart from theta_not, 13 coefficients\n",
    "print(lr.intercept_) # refers to the value of theta_not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 0.727513101678704\n",
      "Testing Score 0.7754582228305665\n"
     ]
    }
   ],
   "source": [
    "# To check how good a model has performed we've a measure of accuracy provided by sklearn\n",
    "# score is basically the coefficient of determination\n",
    "# a score close to 1 is a good model, a score close to zero is a bad model\n",
    "\n",
    "print(\"Training Score\",lr.score(x_train, y_train)) # passed in the training data\n",
    "print(\"Testing Score\",lr.score(x_test, y_test)) # passed in the testing data\n",
    "\n",
    "# we might not get the same score on same dataset every time because train_test_split makes a random split everytime it is called"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
